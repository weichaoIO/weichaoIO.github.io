<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/my_icon.ico"><link rel="icon" href="/img/my_icon.ico"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="魏超"><meta name="keywords" content="魏超,weichao"><meta name="description" content="Reference  Oboe 源代码 Oboe 指南 Oboe API    简介 此示例简单地将音频从输入流循环到输出流，以演示 2 个流接口的用法。 耳返，类似audio-echo，区别就是支持AAudio API。  启动页   可以选择音频输入设备 可以选择音频输出设备 可以选择使用的 API 点击start启动耳返，启动耳返后点击stop关闭耳返   Stream Configura"><meta property="og:type" content="article"><meta property="og:title" content="Android NDK sample 之 LiveEffect"><meta property="og:url" content="https://weichao.io/45e4270bb397/index.html"><meta property="og:site_name" content="『魏超』的 blog"><meta property="og:description" content="Reference  Oboe 源代码 Oboe 指南 Oboe API    简介 此示例简单地将音频从输入流循环到输出流，以演示 2 个流接口的用法。 耳返，类似audio-echo，区别就是支持AAudio API。  启动页   可以选择音频输入设备 可以选择音频输出设备 可以选择使用的 API 点击start启动耳返，启动耳返后点击stop关闭耳返   Stream Configura"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-LiveEffect/Android-NDK-sample-%E4%B9%8B-LiveEffect1.png"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/2.jpg"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/3.jpg"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/4.png"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/5.png"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/6.png"><meta property="og:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-LiveEffect/Android-NDK-sample-%E4%B9%8B-LiveEffect2.jpg"><meta property="article:published_time" content="2021-08-29T07:34:18.000Z"><meta property="article:modified_time" content="2022-12-04T06:04:05.218Z"><meta property="article:author" content="魏超"><meta property="article:tag" content="魏超,weichao"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-LiveEffect/Android-NDK-sample-%E4%B9%8B-LiveEffect1.png"><title>Android NDK sample 之 LiveEffect - 『魏超』的 blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1956623_vyed6le6uz.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"weichao.io",root:"/",version:"1.9.3",typing:{enable:!1,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!1},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:2},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!0,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"kQcwfNV9f5OTEb51AgXNco4o-gzGzoHsz",app_key:"IVVmse4bqkjcVx2bEJiswbJc",server_url:"https://kqcwfnv9.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>『魏超』的 blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-my-home"></i> 首页</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-my-document"></i> 文档</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/archives/"><i class="iconfont icon-my-archive"></i> 归档 </a><a class="dropdown-item" href="/categories/"><i class="iconfont icon-my-category"></i> 分类 </a><a class="dropdown-item" href="/tags/"><i class="iconfont icon-my-tag"></i> 标签</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-my-image"></i> 图库</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/photo/"><i class="iconfont icon-my-camera"></i> 摄影 </a><a class="dropdown-item" href="/skiing/"><i class="iconfont icon-my-skiing"></i> 滑雪 </a><a class="dropdown-item" href="/motor/"><i class="iconfont icon-my-motor"></i> 摩托车</a></div></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-my-me"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="/links/"><i class="iconfont icon-my-link"></i> 友链</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/my_background.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle">Android NDK sample 之 LiveEffect</span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 魏超 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-08-29 15:34" pubdate>2021年8月29日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 26k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 221 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Android NDK sample 之 LiveEffect</h1><p class="note note-info">本文最后更新于：8 天前</p><div class="markdown-body"><h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> <strong>Reference</strong></h1><ul><li><a target="_blank" rel="noopener" href="https://github.com/google/oboe" title="https://github.com/google/oboe">Oboe 源代码</a></li><li><a target="_blank" rel="noopener" href="https://github.com/google/oboe/blob/main/docs/FullGuide.md" title="https://github.com/google/oboe/blob/main/docs/FullGuide.md">Oboe 指南</a></li><li><a target="_blank" rel="noopener" href="https://google.github.io/oboe/reference/namespaceoboe.html" title="https://google.github.io/oboe/reference/namespaceoboe.html">Oboe API</a></li></ul><hr><h1 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> <strong><a target="_blank" rel="noopener" href="https://github.com/google/oboe/tree/main/samples/LiveEffect" title="https://github.com/google/oboe/tree/main/samples/LiveEffect">简介</a></strong></h1><p>此示例简单地将音频从输入流循环到输出流，以演示 2 个流接口的用法。</p><p>耳返，类似<a href="https://weichao.io/2021/08/09/Android-NDK-sample-%E4%B9%8B-audio-echo/" title="https://weichao.io/2021/08/09/Android-NDK-sample-%E4%B9%8B-audio-echo/">audio-echo</a>，区别就是支持AAudio API。</p><h2 id="启动页"><a class="markdownIt-Anchor" href="#启动页"></a> <strong>启动页</strong></h2><p><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-LiveEffect/Android-NDK-sample-%E4%B9%8B-LiveEffect1.png" alt=""></p><ul><li>可以选择音频输入设备</li><li>可以选择音频输出设备</li><li>可以选择使用的 API</li><li>点击<code>start</code>启动耳返，启动耳返后点击<code>stop</code>关闭耳返</li></ul><h2 id="stream-configurations"><a class="markdownIt-Anchor" href="#stream-configurations"></a> <strong>Stream Configurations</strong></h2><ul><li>48kHz</li><li>oboe::I16</li><li>stereo 或 mono</li></ul><h2 id="customizing-the-app"><a class="markdownIt-Anchor" href="#customizing-the-app"></a> <strong>Customizing the App</strong></h2><p>如果要自定义效果处理，请修改“src/main/cpp/FullDuplexPass.h”中的 onBothStreamsReady() 方法</p><h2 id="caveats"><a class="markdownIt-Anchor" href="#caveats"></a> <strong>Caveats</strong></h2><p>同步全双工操作的输入和输出流很棘手。</p><p>输入和输出有不同的启动时间。输入端可能必须为麦克风电路充电。此外，输出回调的初始时间可能会在填充缓冲区时突发。因此，当输出流进行第一次回调时，输入缓冲区可能会溢出或为空或部分已满。</p><p>为了达到同步，我们经历了几个阶段：</p><ul><li>在第 1 阶段，我们总是尽可能多地耗尽输入缓冲区，多于输出回调所要求的。当我们这样做了一段时间后，我们将进入第 2 阶段。</li><li>在阶段 2 中，我们可以选择跳过一次读取输入，以使其充满一次突发。这使得在未来读取时不太可能发生下溢。</li><li>在第 3 阶段，我们应该处于稳定状态，即输出几乎已满而输入几乎为空。您应该能够像这样运行几个小时而不会出现故障。</li></ul><hr><h1 id="oboe-基础"><a class="markdownIt-Anchor" href="#oboe-基础"></a> <strong>Oboe 基础</strong></h1><p>Oboe 是一个 C++ 库，可以轻松地在 Android 上构建高性能音频应用程序。应用程序通过向流读取和写入数据来与 Oboe 通信。</p><h2 id="audio-streams"><a class="markdownIt-Anchor" href="#audio-streams"></a> <strong>Audio streams</strong></h2><p>Oboe 在您的应用程序与 Android 设备上的音频输入和输出之间移动音频数据。您的应用程序使用回调函数或通过读取和写入音频流来传入和传出数据，由类 AudioStream 表示。读/写调用可以是阻塞的或非阻塞的。</p><p>流由以下定义：</p><ul><li><code>audio device</code>作为流中数据的源或接收器。</li><li><code>sharing mode</code>确定流是否对音频设备具有独占访问权限，否则该音频设备可能会在多个流之间共享。</li><li><code>format</code>是流中的音频数据。</li></ul><h3 id="audio-device"><a class="markdownIt-Anchor" href="#audio-device"></a> <strong>Audio device</strong></h3><p>每个流都附加到单个音频设备。</p><p>音频设备是硬件接口或虚拟端点，充当连续数字音频数据流的源或接收器。不要将音频设备（内置麦克风或蓝牙耳机）与运行您的应用的 Android 设备（手机或手表）混淆。</p><p>在 API 23 及更高版本上，您可以使用 AudioManager 方法 getDevices() 来发现 Android 设备上可用的音频设备。该方法返回有关每个设备类型的信息。</p><p>每个音频设备在 Android 设备上都有一个唯一的 ID。您可以使用 ID 将音频流绑定到特定的音频设备。但是，在大多数情况下，您可以让 Oboe 选择默认的主要设备，而不是自己指定一个。</p><p>连接到流的音频设备确定流是用于输入还是输出。一个流只能在一个方向上移动数据。当你定义一个流时，你也设置了它的方向。当您打开一个流时，Android 会检查以确保音频设备和流方向一致。</p><h3 id="sharing-mode"><a class="markdownIt-Anchor" href="#sharing-mode"></a> <strong>Sharing mode</strong></h3><p>流具有共享模式：</p><ul><li><code>SharingMode::Exclusive</code>独家的（在 API 26+ 上可用）：意味着流可以独占访问其音频设备上的端点；端点不能被任何其他音频流使用。如果独占端点已在使用中，则流可能无法访问它。独占流通过绕过混合器阶段提供尽可能低的延迟，但它们也更有可能断开连接。您应该在不再需要它们时立即关闭独占流，以便其他应用程序可以访问该端点。并非所有音频设备都提供独占端点。系统声音和来自其他应用程序的声音在使用独占流时仍然可以听到，因为它们使用不同的端点。<br><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/2.jpg" alt=""></li><li><code>SharingMode::Shared</code>共享的：允许 Oboe 流共享一个端点。操作系统将混合分配给音频设备上同一端点的所有共享流。<br><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/3.jpg" alt=""></li></ul><p>您可以在创建流时明确请求共享模式，但不能保证您会收到该模式。默认情况下，共享模式为 Shared。</p><h3 id="audio-format"><a class="markdownIt-Anchor" href="#audio-format"></a> <strong>Audio format</strong></h3><p>通过流传递的数据具有通常的数字音频属性，您必须在定义流时指定这些属性。这些如下：</p><ul><li>Sample format</li><li>Samples per frame</li><li>Sample rate</li></ul><p>Oboe 允许这些 Sample format：</p><p>AudioFormat|C data type|Notes<br>–|–<br>I16|int16_t|common 16-bit samples, Q0.15 format<br>Float|float|-1.0 to +1.0</p><p>Oboe 可能会自行执行采样转换。例如，如果应用程序正在写入 AudioFormat::Float 数据，但 HAL 使用 AudioFormat::I16，则 Oboe 可能会自动转换采样。转换可以发生在任一方向。如果您的应用程序处理音频输入，那么验证输入格式并准备好在必要时转换数据是明智的，如下例所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C">AudioFormat dataFormat = stream-&gt;getDataFormat();<br><span class="hljs-comment">//... later</span><br><span class="hljs-keyword">if</span> (dataFormat == AudioFormat::I16) &#123;<br>     convertFloatToPcm16(...)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="creating-an-audio-stream"><a class="markdownIt-Anchor" href="#creating-an-audio-stream"></a> <strong>Creating an audio stream</strong></h2><p>Oboe 库遵循构建器设计模式并提供类 AudioStreamBuilder。</p><h3 id="set-the-audio-stream-configuration-using-an-audiostreambuilder"><a class="markdownIt-Anchor" href="#set-the-audio-stream-configuration-using-an-audiostreambuilder"></a> <strong>Set the audio stream configuration using an AudioStreamBuilder.</strong></h3><p>使用与流参数对应的构建器函数。这些可选的设置功能可用：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C">AudioStreamBuilder streamBuilder;<br><br>streamBuilder.setDeviceId(deviceId);<br>streamBuilder.setDirection(direction);<br>streamBuilder.setSharingMode(shareMode);<br>streamBuilder.setSampleRate(sampleRate);<br>streamBuilder.setChannelCount(channelCount);<br>streamBuilder.setFormat(format);<br>streamBuilder.setPerformanceMode(perfMode);<br></code></pre></td></tr></table></figure><p>请注意，这些方法不会报告错误，例如未定义的常量或值超出范围。当流打开时，它们将被检查。</p><p>如果不指定 deviceId，则默认为主要输出设备。如果不指定流方向，则默认为输出流。对于所有参数，您可以明确设置一个值，或者通过根本不指定参数或将其设置为 kUnspecified 来让系统分配最佳值。</p><p>为安全起见，请在创建音频流后检查其状态，如下面的第 3 步所述。</p><h3 id="open-the-stream"><a class="markdownIt-Anchor" href="#open-the-stream"></a> <strong>Open the Stream</strong></h3><p>配置 AudioStreamBuilder 后，调用 openStream() 打开流：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C">Result result = streamBuilder.openStream(&amp;stream_);<br><span class="hljs-keyword">if</span> (result != OK)&#123;<br>    __android_log_print(ANDROID_LOG_ERROR, <span class="hljs-string">&quot;AudioEngine&quot;</span>, <span class="hljs-string">&quot;Error opening stream %s&quot;</span>, convertToText(result));<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="verifying-stream-configuration-and-additional-properties"><a class="markdownIt-Anchor" href="#verifying-stream-configuration-and-additional-properties"></a> <strong>Verifying stream configuration and additional properties</strong></h3><p>您应该在打开流后验证它的配置。</p><p>保证设置以下属性。但是，如果未指定这些属性，则仍将设置默认值，并应由适当的访问器查询。</p><ul><li>framesPerCallback</li><li>sampleRate</li><li>channelCount</li><li>format</li><li>direction</li></ul><p>即使显式设置以下属性也可能由底层流构造更改，因此应始终由适当的访问器查询。属性设置将取决于设备功能。</p><ul><li>bufferCapacityInFrames</li><li>sharingMode (exclusive provides lowest latency)</li><li>performanceMode</li></ul><p>以下属性仅由底层流设置。它们不能由应用程序设置，但应由适当的访问器查询。</p><ul><li>framesPerBurst</li></ul><p>以下属性具有异常行为</p><ul><li>deviceId 的值，当底层 API 为 AAudio（API 级别 &gt;=28）时才会生效，当使用 OpenSLES 时设置是无效的。当使用 OpenSLES 时，无论如何设置 deviceId 都不会抛出错误，并且会使用默认设备，而不是指定的任何设备。</li><li>mAudioApi 只是构建器的一个属性，但是 AudioStream::getAudioApi() 可用于查询流使用的底层 API。构建器中设置的属性不能保证，一般情况下，API 应该由 Oboe 选择，以考虑最佳性能和稳定性。由于 Oboe 设计为在两个 API 之间尽可能统一，因此通常不需要此属性。</li><li>mBufferSizeInFrames 只能在已经打开的流上设置（与构建器相反），因为它取决于运行时行为。实际使用的大小可能不是所要求的大小。Oboe 或底层 API 将限制零和缓冲区容量之间的大小。还可以进一步限制以减少特定设备上的毛刺。将回调与 OpenSL ES 结合使用时，不支持此功能。</li></ul><p>许多流的属性可能会有所不同（无论您是否设置它们），具体取决于音频设备的功能和运行它的 Android 设备。如果您需要知道这些值，则必须在打开流后使用访问器查询它们。此外，授予流的基础参数有助于了解它们是否未指定。作为一个好的防御性编程问题，您应该在使用之前检查流的配置。</p><p>有一些函数可以检索与每个构建器设置对应的流设置：</p><table><thead><tr><th>AudioStreamBuilder set methods</th><th>AudioStream get methods</th></tr></thead><tbody><tr><td>setDataCallback()</td><td>getDataCallback()</td></tr><tr><td>setErrorCallback()</td><td>getErrorCallback()</td></tr><tr><td>setDirection()</td><td>getDirection()</td></tr><tr><td>setSharingMode()</td><td>getSharingMode()</td></tr><tr><td>setPerformanceMode()</td><td>getPerformanceMode()</td></tr><tr><td>setSampleRate()</td><td>getSampleRate()</td></tr><tr><td>setChannelCount()</td><td>getChannelCount()</td></tr><tr><td>setFormat()</td><td>getFormat()</td></tr><tr><td>setBufferCapacityInFrames()</td><td>getBufferCapacityInFrames()</td></tr><tr><td>setFramesPerCallback()</td><td>getFramesPerCallback()</td></tr><tr><td>-</td><td>getFramesPerBurst()</td></tr><tr><td>setDeviceId() (not respected on OpenSLES)</td><td>getDeviceId()</td></tr><tr><td>setAudioApi() (mainly for debugging)</td><td>getAudioApi()</td></tr></tbody></table><p>API 28 中添加了以下 AudioStreamBuilder 字段，以指定有关设备的 AudioStream 的其他信息。目前，它们对流的影响很小，但设置它们有助于应用程序更好地与其他服务交互。</p><p>有关更多信息，请参阅：Usage/ContentTypes。 设备可以使用 InputPreset 来处理输入流（例如增益控制）。默认情况下，它设置为 VoiceRecognition，它针对低延迟进行了优化。</p><ul><li>setUsage(oboe::Usage usage) - 创建流的目的。</li><li>setContentType(oboe::ContentType contentType) - 流承载的内容类型。</li><li>setInputPreset(oboe::InputPreset inputPreset) - 音频输入的录音配置。</li><li>setSessionId(SessionId sessionId) - 分配 SessionID 以连接到 Java AudioEffects API。</li></ul><h2 id="using-an-audio-stream"><a class="markdownIt-Anchor" href="#using-an-audio-stream"></a> <strong>Using an audio stream</strong></h2><h3 id="state-transitions"><a class="markdownIt-Anchor" href="#state-transitions"></a> <strong>State transitions</strong></h3><p>Oboe 流通常处于五种稳定状态之一（错误状态，断开连接，在本节末尾描述）：</p><ul><li>Open</li><li>Started</li><li>Paused</li><li>Flushed</li><li>Stopped</li></ul><p>数据仅在流处于已启动状态时流过流。要在状态之间移动流，请使用请求状态转换的函数之一：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C">Result result;<br>result = stream-&gt;requestStart();<br>result = stream-&gt;requestStop();<br>result = stream-&gt;requestPause();<br>result = stream-&gt;requestFlush();<br></code></pre></td></tr></table></figure><p>请注意，您只能在输出流上请求暂停或刷新：</p><p>这些函数是异步的，状态更改不会立即发生。当您请求状态更改时，流将移动到相应的瞬态之一：</p><ul><li>Starting</li><li>Pausing</li><li>Flushing</li><li>Stopping</li><li>Closing</li></ul><p>下面的状态图将稳定状态显示为圆角矩形，将瞬态显示为虚线矩形。尽管未显示，但您可以从任何状态调用 close()<br><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/4.png" alt=""></p><p>Oboe 不提供回调来提醒您状态变化。一种特殊函数 AudioStream::waitForStateChange() 可用于等待状态更改。请注意，大多数应用程序不需要调用 waitForStateChange() 并且可以在需要时请求状态更改。</p><p>该函数不会自行检测状态变化，也不会等待特定状态。它一直等到当前状态与您指定的 inputState 不同。</p><p>例如，在请求暂停后，流应该立即进入暂时状态 Pausing，并在稍后到达 Paused 状态 - 尽管不能保证它会。由于不能等待 Paused 状态，因此使用 waitForStateChange() 等待除 Pausing 之外的任何状态。这是如何做到的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C">StreamState inputState = StreamState::Pausing;<br>StreamState nextState = StreamState::Uninitialized;<br><span class="hljs-type">int64_t</span> timeoutNanos = <span class="hljs-number">100</span> * kNanosPerMillisecond;<br>result = stream-&gt;requestPause();<br>result = stream-&gt;waitForStateChange(inputState, &amp;nextState, timeoutNanos);<br></code></pre></td></tr></table></figure><p>如果流的状态不是 Pausing（输入状态，我们假设它是调用时的当前状态），函数立即返回。否则，它会阻塞，直到状态不再是 Pausing 或超时到期。当函数返回时，参数 nextState 显示流的当前状态。</p><p>您可以在调用 request start、stop 或 flush 之后使用相同的技术，使用相应的瞬态作为 inputState。不要在调用 AudioStream::close() 后调用 waitForStateChange()，因为一旦关闭，底层流资源将被删除。并且不要在另一个线程中运行 waitForStateChange() 时调用 close()。</p><h3 id="reading-and-writing-to-an-audio-stream"><a class="markdownIt-Anchor" href="#reading-and-writing-to-an-audio-stream"></a> <strong>Reading and writing to an audio stream</strong></h3><p>有两种方法可以将数据移入或移出流。</p><ol><li>从流中读取或直接写入流。</li><li>指定一个数据回调对象，当流准备好时会被调用。</li></ol><p>回调技术提供最低的延迟性能，因为回调代码可以在高优先级线程中运行。此外，尝试在没有音频回调的情况下打开低延迟输出流（意图使用写入）可能会导致非低延迟流。</p><p>当您不需要低延迟时，读/写技术可能更容易。或者，当同时进行输入和输出时，通常使用回调进行输出，然后从输入流中进行非阻塞读取。然后，您可以在一个高优先级线程中获得输入和输出数据。</p><p>流启动后，您可以使用 AudioStream::read(buffer, numFrames, timeoutNanos) 和 AudioStream::write(buffer, numFrames, timeoutNanos) 方法对其进行读取或写入。</p><p>对于传输指定帧数的阻塞读取或写入，请将 timeoutNanos 设置为大于零。对于非阻塞调用，将 timeoutNanos 设置为零。在这种情况下，结果是实际传输的帧数。</p><p>当您读取输入时，您应该验证读取的帧数是否正确。否则，缓冲区可能包含可能导致音频故障的未知数据。您可以用零填充缓冲区以创建静默丢失：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C">Result result = stream.read(audioData, numFrames, timeout);<br><span class="hljs-keyword">if</span> (result &lt; <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-comment">// Error!</span><br>&#125;<br><span class="hljs-keyword">if</span> (result != numFrames) &#123;<br>    <span class="hljs-comment">// pad the buffer with zeros</span><br>    <span class="hljs-built_in">memset</span>(static_cast&lt;sample_type*&gt;(audioData) + result * samplesPerFrame, <span class="hljs-number">0</span>, (numFrames - result) * stream.getBytesPerFrame());<br>&#125;<br></code></pre></td></tr></table></figure><p>您可以在启动流之前通过向其中写入数据或静默来填充流的缓冲区。这必须在 timeoutNanos 设置为零的非阻塞调用中完成。</p><p>缓冲区中的数据必须与 stream.getDataFormat() 返回的数据格式匹配。</p><h3 id="closing-an-audio-stream"><a class="markdownIt-Anchor" href="#closing-an-audio-stream"></a> <strong>Closing an audio stream</strong></h3><p>使用完流后，将其关闭：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C">stream-&gt;close();<br></code></pre></td></tr></table></figure><p>不要在流被另一个线程写入或读取时关闭它，因为这会导致您的应用程序崩溃。关闭流后，除了查询其属性外，不应调用其任何方法。</p><h3 id="disconnected-audio-stream"><a class="markdownIt-Anchor" href="#disconnected-audio-stream"></a> <strong>Disconnected audio stream</strong></h3><p>如果发生以下事件之一，音频流可能随时断开连接：</p><ul><li>不再连接关联的音频设备（例如，拔下耳机时）。</li><li>内部发生错误。</li><li>音频设备不再是主要的音频设备。</li></ul><p>当流断开连接时，它具有&quot;Disconnected&quot;状态并且调用 write() 或其他函数将返回 Result::ErrorDisconnected。当流断开连接时，您所能做的就是关闭它。</p><p>如果您需要在音频设备断开连接时收到通知，请编写一个扩展 AudioStreamErrorCallback 的类，然后使用 builder.setErrorCallback(yourCallbackClass) 注册您的类。如果您注册一个回调，那么如果流断开连接，它将在单独的线程中自动关闭流。</p><p>您的回调可以实现以下方法（在单独的线程中调用）：</p><ul><li>onErrorBeforeClose(stream, error) - 当流已断开但尚未关闭时调用，因此您仍然可以引用底层流（例如getXRunCount()）。您还可以通知可能正在调用流的任何其他线程停止这样做。不要在此回调中删除流或修改其流状态。</li><li>onErrorAfterClose(stream, error) - 当流被 Oboe 停止并关闭时调用，因此无法使用流并且调用 getState() 将返回closed。在此回调期间，可以查询流属性（构建器请求的属性）以及写入和读取的帧。可以在此方法结束时删除流（只要它没有在其他线程中引用）。不应调用引用底层流的方法（例如 getTimestamp()、getXRunCount()、read()、write() 等）。打开一个单独的流也是这个回调的合理使用，特别是如果收到的错误是 Error::Disconnected。但是，重要的是要注意，新的音频设备可能与断开连接的流具有截然不同的属性。</li></ul><h2 id="optimizing-performance"><a class="markdownIt-Anchor" href="#optimizing-performance"></a> <strong>Optimizing performance</strong></h2><p>您可以通过使用特殊的高优先级线程来优化音频应用程序的性能。</p><h3 id="using-a-high-priority-data-callback"><a class="markdownIt-Anchor" href="#using-a-high-priority-data-callback"></a> <strong>Using a high priority data callback</strong></h3><p>如果您的应用程序从普通线程读取或写入音频数据，则可能会被抢占或遇到时序抖动。这可能会导致音频故障。使用较大的缓冲区可能会防止出现此类故障，但较大的缓冲区也会引入更长的音频延迟。对于需要低延迟的应用程序，音频流可以使用异步回调函数与您的应用程序传输数据。回调在具有更好性能的高优先级线程中运行。</p><p>您的代码可以通过实现虚拟类 AudioStreamDataCallback 来访问回调机制。该流定期执行 onAudioReady()（回调函数）以获取其下一次突发的数据。</p><p>您需要填充的采样总数为 numFrames * numChannels。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AudioEngine</span> :</span> AudioStreamDataCallback &#123;<br>public:<br>    DataCallbackResult <span class="hljs-title function_">AudioEngine::onAudioReady</span><span class="hljs-params">(AudioStream *oboeStream, <span class="hljs-type">void</span> *audioData, <span class="hljs-type">int32_t</span> numFrames)</span>&#123;<br>        <span class="hljs-comment">// Fill the output buffer with random white noise.</span><br>        <span class="hljs-type">const</span> <span class="hljs-type">int</span> numChannels = AAudioStream_getChannelCount(stream);<br>        <br>        <span class="hljs-comment">// This code assumes the format is AAUDIO_FORMAT_PCM_FLOAT.</span><br>        <span class="hljs-type">float</span> *output = (<span class="hljs-type">float</span> *)audioData;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> frameIndex = <span class="hljs-number">0</span>; frameIndex &lt; numFrames; frameIndex++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> channelIndex = <span class="hljs-number">0</span>; channelIndex &lt; numChannels; channelIndex++) &#123;<br>                <span class="hljs-type">float</span> noise = (<span class="hljs-type">float</span>)(drand48() - <span class="hljs-number">0.5</span>);<br>                *output++ = noise;<br>            &#125;<br>        &#125;<br>        <br>        <span class="hljs-keyword">return</span> DataCallbackResult::Continue;<br>    &#125;<br><br>    <span class="hljs-type">bool</span> <span class="hljs-title function_">AudioEngine::start</span><span class="hljs-params">()</span> &#123;<br>        ...<br>        <span class="hljs-comment">// register the callback</span><br>        streamBuilder.setDataCallback(this);<br>    &#125;<br>private:<br>    <span class="hljs-comment">// application data goes here</span><br>&#125;<br></code></pre></td></tr></table></figure><p>请注意，回调必须使用 setDataCallback 在流上注册。任何特定于应用程序的数据都可以包含在类本身中。</p><p>回调函数不应对调用它的流执行读取或写入操作。如果回调属于输入流，则您的代码应处理 audioData 缓冲区中提供的数据（指定为第二个参数）。如果回调属于输出流，则您的代码应将数据放入缓冲区。</p><p>在回调中可以处理多个流。您可以使用一个流作为主数据流，并在类的私有数据中将指针传递给其他流。为主流注册回调。然后在其他流上使用非阻塞 I/O。这是将输入流传递到输出流的往返回调的示例。主调用流是输出流。输入流包含在类中。</p><p>回调从输入流中进行非阻塞读取，将数据放入输出流的缓冲区中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AudioEngine</span> :</span> AudioStreamDataCallback &#123;<br>public:<br><br>    DataCallbackResult <span class="hljs-title function_">AudioEngine::onAudioReady</span><span class="hljs-params">(AudioStream *oboeStream, <span class="hljs-type">void</span> *audioData, <span class="hljs-type">int32_t</span> numFrames)</span> &#123;<br>        <span class="hljs-type">const</span> <span class="hljs-type">int64_t</span> timeoutNanos = <span class="hljs-number">0</span>; <span class="hljs-comment">// for a non-blocking read</span><br>        <span class="hljs-keyword">auto</span> result = recordingStream-&gt;read(audioData, numFrames, timeoutNanos);<br>        <span class="hljs-comment">// result has type ResultWithValue&lt;int32_t&gt;, which for convenience is coerced to a Result type when compared with another Result.</span><br>        <span class="hljs-keyword">if</span> (result == Result::OK) &#123;<br>            <span class="hljs-keyword">if</span> (result.value() &lt; numFrames) &#123;<br>                <span class="hljs-comment">// replace the missing data with silence</span><br>                <span class="hljs-built_in">memset</span>(static_cast&lt;sample_type*&gt;(audioData) + result.value() * samplesPerFrame, <span class="hljs-number">0</span>, (numFrames - result.value()) * oboeStream-&gt;getBytesPerFrame());<br>            &#125;<br>            <span class="hljs-keyword">return</span> DataCallbackResult::Continue;<br>        &#125;<br>        <span class="hljs-keyword">return</span> DataCallbackResult::Stop;<br>    &#125;<br><br>    <span class="hljs-type">bool</span> <span class="hljs-title function_">AudioEngine::start</span><span class="hljs-params">()</span> &#123;<br>        ...<br>        streamBuilder.setDataCallback(this);<br>    &#125;<br><br>    <span class="hljs-type">void</span> <span class="hljs-title function_">setRecordingStream</span><span class="hljs-params">(AudioStream *stream)</span> &#123;<br>      recordingStream = stream;<br>    &#125;<br><br>private:<br>    AudioStream *recordingStream;<br>&#125;<br></code></pre></td></tr></table></figure><p>请注意，在此示例中，假设输入和输出流具有相同数量的通道、格式和采样率。流的格式可能不匹配 - 只要代码正确处理翻译。</p><h4 id="data-callback-dos-and-donts"><a class="markdownIt-Anchor" href="#data-callback-dos-and-donts"></a> <strong>Data Callback - Do’s and Don’ts</strong></h4><p>您永远不应该执行可能在 onAudioReady 内部阻塞的操作。阻塞操作的例子包括：</p><ul><li>使用例如 malloc() 或 new 分配内存</li><li>文件操作，例如打开、关闭、读取或写入</li><li>网络操作，如流媒体</li><li>使用互斥锁或其他同步原语</li><li>sleep</li><li>停止或关闭流</li><li>在调用它的流上调用 read() 或 write()</li></ul><p>但是以下方法都可以调用：</p><ul><li>AudioStream::get*()</li><li>oboe::convertResultToText()</li></ul><h3 id="setting-performance-mode"><a class="markdownIt-Anchor" href="#setting-performance-mode"></a> <strong>Setting performance mode</strong></h3><p>每个 AudioStream 都有一个性能模式，它对你的应用程序的行为有很大的影响。 共有三种模式：</p><ul><li><code>PerformanceMode::None</code>是默认模式。它使用平衡延迟和节能的基本流。</li><li><code>PerformanceMode::LowLatency</code>使用较小的缓冲区和优化的数据路径来减少延迟。</li><li><code>PerformanceMode::PowerSaving</code>使用更大的内部缓冲区和数据路径，以牺牲延迟换取低功耗。</li></ul><p>您可以通过调用 setPerformanceMode() 选择性能模式，并通过调用 getPerformanceMode() 发现当前模式。</p><p>如果应用程序中低延迟比节能更重要，请使用 PerformanceMode::LowLatency。这对于交互性很强的应用程序非常有用，例如游戏或键盘合成器。</p><p>如果在您的应用程序中节能比低延迟更重要，请使用 PerformanceMode::PowerSaving。这对于播放以前生成的音乐的应用程序来说很典型，例如流式音频或 MIDI 文件播放器。</p><p>在当前版本的 Oboe 中，为了实现尽可能低的延迟，您必须使用 PerformanceMode::LowLatency 性能模式以及高优先级数据回调。 按照这个例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-comment">// Create a callback object</span><br>MyOboeStreamCallback myCallback;<br><br><span class="hljs-comment">// Create a stream builder</span><br>AudioStreamBuilder builder;<br>builder.setDataCallback(myCallback);<br>builder.setPerformanceMode(PerformanceMode::LowLatency);<br><br><span class="hljs-comment">// Use it to create the stream</span><br>AudioStream *stream;<br>builder.openStream(&amp;stream);<br></code></pre></td></tr></table></figure><h2 id="thread-safety"><a class="markdownIt-Anchor" href="#thread-safety"></a> <strong>Thread safety</strong></h2><p>Oboe API 不是完全线程安全的。您不能一次从多个线程同时调用某些 Oboe 函数。这是因为 Oboe 避免使用互斥体，这会导致线程抢占和故障。</p><p>为安全起见，不要调用 waitForStateChange() 或从两个不同的线程读取或写入同一流。同样，不要在另一个线程中读取或写入流时关闭一个线程中的流。</p><p>返回流设置的调用，如 AudioStream::getSampleRate() 和 AudioStream::getChannelCount()，是线程安全的。</p><p>这些调用也是线程安全的：</p><ul><li>convertToText()</li><li>AudioStream::get*()，除了 getTimestamp() 和 getState()</li></ul><p>注意：当流使用错误回调时，从回调线程读/写是安全的，同时也从运行它的线程关闭流。</p><h2 id="api"><a class="markdownIt-Anchor" href="#api"></a> <strong>API</strong></h2><h3 id="oboeaudiostreambase"><a class="markdownIt-Anchor" href="#oboeaudiostreambase"></a> <strong>oboe::AudioStreamBase</strong></h3><p>包含音频流和构建器参数的基类。</p><p><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/5.png" alt=""></p><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>  |AudioStreamBase (const AudioStreamBase &amp;)=default|默认复制构造函数<br>AudioStreamBase &amp; |operator= (const AudioStreamBase &amp;)=default|默认赋值运算符<br>int32_t |getChannelCount () const|返回通道数|例如 2 表示立体声，或 kUnspecified<br>Direction |getDirection () const|返回Direction::Input或Direction::Output<br>int32_t |getSampleRate () const|返回流的采样率或 kUnspecified<br>int32_t |getFramesPerDataCallback () const|返回每个数据回调或 kUnspecified 中的帧数。<br>AudioFormat |getFormat () const|返回音频采样格式（例如 Float 或 I16）<br>virtual int32_t |getBufferSizeInFrames ()|查询不阻塞可以填充的最大帧数。|如果流已关闭，则将返回最后一个已知值。<br>virtual int32_t |getBufferCapacityInFrames () const|返回 capacityInFrames 或 kUnspecified<br>SharingMode |getSharingMode () const|返回流的共享模式。<br>PerformanceMode |getPerformanceMode () const|返回流的性能模式。<br>int32_t |getDeviceId () const|返回流的设备 ID。<br>AudioStreamDataCallback * |getDataCallback () const|如果设置，则返回此流的数据回调对象。|仅限内部使用。<br>AudioStreamErrorCallback * |getErrorCallback () const|如果设置，则返回此流的错误回调对象。|仅限内部使用。<br>bool |isDataCallbackSpecified () const|如果为此流设置了数据回调，则返回 true<br>bool |isErrorCallbackSpecified () const|如果为此流设置了错误回调，则返回 true|请注意，如果应用程序未设置错误回调，则可能会提供默认回调。<br>Usage |getUsage () const|返回此流的使用情况。<br>ContentType |getContentType () const|返回流的内容类型。<br>InputPreset |getInputPreset () const|返回流的输入预设。<br>SessionId |getSessionId () const|返回流的会话 ID 分配策略（无或分配）。<br>bool |isChannelConversionAllowed () const|如果 Oboe 可以转换通道计数以获得最佳结果，则返回 true。<br>bool |isFormatConversionAllowed () const|如果 Oboe 可以转换数据格式以获得最佳结果，则返回 true。<br>SampleRateConversionQuality |getSampleRateConversionQuality () const|返回 Oboe 是否以及如何转换采样率以获得最佳结果。</p><p><strong>Protected</strong></p><p>返回值|函数|描述<br>–|–<br>virtual Result |isValidConfig ()|验证在较低层中可能未检查的流参数</p><h3 id="oboeaudiostream"><a class="markdownIt-Anchor" href="#oboeaudiostream"></a> <strong>oboe::AudioStream</strong></h3><p>Oboe C++ 音频流的基类。</p><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>  |AudioStream (const AudioStreamBuilder &amp;builder)|使用给定的 AudioStreamBuilder 构造一个 AudioStream<br>virtual Result |open ()|根据当前设置打开一个流。|请注意，我们不建议重新打开已关闭的流。 TODO 我们应该阻止重新开放吗？<br>virtual Result |close ()|关闭流并从 open() 调用中释放任何资源。<br>virtual Result |start (int64_t timeoutNanoseconds=kDefaultTimeoutNanos)|启动流。|这将阻塞，直到流已启动、发生错误或已达到 timeoutNanoseconds。<br>virtual Result |pause (int64_t timeoutNanoseconds=kDefaultTimeoutNanos)|暂停流。|这将阻塞，直到流暂停、发生错误或达到 timeoutNanoseconds。<br>virtual Result |flush (int64_t timeoutNanoseconds=kDefaultTimeoutNanos)|刷新流。|这将阻塞，直到流被刷新、发生错误或达到 timeoutNanoseconds。<br>virtual Result |stop (int64_t timeoutNanoseconds=kDefaultTimeoutNanos)|停止流。|这将阻塞，直到流停止、发生错误或达到 timeoutNanoseconds。<br>virtual Result |requestStart ()=0|异步启动流。|立即返回（不阻塞）。相当于调用start(0)。<br>virtual Result |requestPause ()=0|异步暂停流。|立即返回（不阻塞）。相当于调用pause(0)。<br>virtual Result |requestFlush ()=0|异步刷新流。|立即返回（不阻塞）。相当于调用flush(0)。<br>virtual Result |requestStop ()=0|异步停止流。|立即返回（不阻塞）。相当于调用 stop(0)。<br>virtual StreamState |getState () const =0|查询当前状态，例如StreamState::Pausing<br>virtual Result |waitForStateChange (StreamState inputState, StreamState *nextState, int64_t timeoutNanoseconds)=0|等到流的当前状态不再与输入状态匹配。传递输入状态是为了避免由调用之间的状态变化引起的竞争条件。|请注意，通常应用程序不需要调用它。它被认为是一种先进的技术，主要用于测试。<br>如果状态在超时期限内没有改变，那么它将返回 ErrorTimeout。即使 timeoutNanoseconds 为零也是如此。<br>virtual ResultWithValue&lt; int32_t &gt; |setBufferSizeInFrames (int32_t)|这可用于通过更改将发生阻塞的阈值来调整缓冲区的延迟。|通过将其与 getXRunCount() 相结合，可以在运行时为每个设备调整延迟。<br>这不能设置为高于 getBufferCapacity()。<br>virtual ResultWithValue&lt; int32_t &gt; |getXRunCount () const|XRun 是欠载或超载。在播放过程中，如果没有及时写入流，并且系统没有有效数据，就会发生欠载。在记录过程中，如果没有及时读取流，并且没有地方放置传入的数据，则会发生溢出，因此将其丢弃。|欠载或超载会导致可听见的“爆裂声”或“故障”。<br>virtual bool |isXRunCountSupported () const =0|如果流支持 XRun 计数，则返回 true<br>virtual int32_t |getFramesPerBurst ()=0|查询端点一次读写的帧数。<br>int32_t |getBytesPerFrame () const|获取每个音频帧中的字节数。|这是使用通道计数和样本格式计算的。例如，一个 2 通道浮点流每帧将有 2 * 4 = 8 个字节。<br>int32_t |getBytesPerSample () const|获取每个样本的字节数。|这是使用示例格式计算的。例如，使用 16 位整数样本的流每个样本将有 2 个字节。<br>virtual int64_t |getFramesWritten ()|写入流的音频帧数。|这个单调计数器永远不会被重置。<br>virtual int64_t |getFramesRead ()|从流中读取的音频帧数。|这个单调计数器永远不会被重置。<br>virtual ResultWithValue&lt; double &gt; |calculateLatencyMillis ()|基于 getTimestamp() 计算流的延迟。|输出延迟是给定帧从应用程序传输到某种类型的数模转换器所需的时间。如果 DAC 是外部的，例如在 USB 接口或通过 HDMI 连接的电视中，则可能存在 Android 设备不知道的额外延迟。<br>输入延迟是给定帧从模数转换器 (ADC) 传输到应用程序所需的时间。<br>请注意，当您向 OUTPUT 流写入数据时，它的延迟会突然增加，然后随着数据的消耗而缓慢减少。<br>当您从中读取数据时，INPUT 流的延迟会突然减少，然后随着更多数据的到达而缓慢增加。<br>OUTPUT 流的延迟通常高于 INPUT 延迟，因为应用程序通常会尝试保持 OUTPUT 缓冲区已满而 INPUT 缓冲区为空。<br>virtual ResultWithValue&lt; FrameTimestamp &gt; |getTimestamp (clockid_t)|获取 framePosition 处的帧进入或离开音频处理管道的估计时间。|这可用于协调事件和与外部环境的交互，并估计音频流的延迟。<br>virtual ResultWithValue&lt; int32_t &gt; |write (const void *, int32_t, int64_t)|将提供的缓冲区中的数据写入流中。|此方法将阻塞，直到写入完成或超时。<br>如果 timeoutNanoseconds 为零，则此调用将不会等待。<br>virtual ResultWithValue&lt; int32_t &gt; |read (void *, int32_t, int64_t)|从流中将数据读入提供的缓冲区。|此方法将阻塞，直到读取完成或超时。<br>如果 timeoutNanoseconds 为零，则此调用将不会等待。<br>virtual AudioApi |getAudioApi () const =0|获取流使用的底层音频 API。<br>bool |usesAAudio () const|如果底层音频 API 是 Audio，则返回 true。<br>void |launchStopThread ()|启动一个线程用于停止流<br>virtual void |updateFramesWritten ()=0|更新 mFramesWritten。|仅限内部使用。<br>virtual void |updateFramesRead ()=0|更新 mFramesRead。|仅限内部使用。<br>AudioStreamDataCallback * |swapDataCallback (AudioStreamDataCallback *dataCallback)|<br>AudioStreamErrorCallback * |swapErrorCallback (AudioStreamErrorCallback *errorCallback)|<br>ResultWithValue&lt; int32_t &gt; |getAvailableFrames ()|返回当前缓冲区中的数据帧数<br>ResultWithValue&lt; int32_t &gt; |waitForAvailableFrames (int32_t numFrames, int64_t timeoutNanoseconds)|等到流的缓冲区中有最少量的可用数据。|这可以与 EXCLUSIVE MMAP 输入流一起使用，以避免读取数据太靠近 DSP 写入位置，这可能会导致故障。<br>virtual oboe::Result |getLastErrorCallbackResult () const|返回从错误回调传递的最后一个结果</p><p><strong>Protected</strong></p><p>返回值|函数|描述|评论<br>–|–<br>bool |wasErrorCallbackCalled ()|这用于从流中检测多个错误回调。|在某些 Android 版本中有一些bug会触发多次错误回调。<br>调用它会设置 atomic<bool>为真并返回前一个值。<br>virtual Result |waitForStateTransition (StreamState startingState, StreamState endingState, int64_t timeoutNanoseconds)|等待从一种状态转换到另一种状态。<br>virtual DataCallbackResult |onDefaultCallback (void *, int)|覆盖它以提供应用程序未指定回调时的默认值。<br>DataCallbackResult |fireDataCallback (void *audioData, int numFrames)|覆盖它以提供您自己的音频回调行为<br>bool |isDataCallbackEnabled ()|如果可以调用回调，则返回 true<br>void |setDataCallbackEnabled (bool enabled)|这可以在内部设置为 false 以防止在返回 DataCallbackResult::Stop 后回调。<br>void |setWeakThis (std::shared_ptr&lt; oboe::AudioStream &gt; &amp;sharedStream)|<br>std::shared_ptr&lt; oboe::AudioStream &gt; |lockWeakThis ()|</bool></p><h3 id="oboeaudiostreambuilder"><a class="markdownIt-Anchor" href="#oboeaudiostreambuilder"></a> <strong>oboe::AudioStreamBuilder</strong></h3><p>音频流的工厂类。</p><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>  |AudioStreamBuilder (const AudioStreamBase &amp;audioStreamBase)|<br>AudioStreamBuilder * |setChannelCount (int channelCount)|请求特定数量的频道。|默认值为 kUnspecified。如果未指定值，则应用程序应在打开流后查询实际值。<br>AudioStreamBuilder * |setDirection (Direction direction)|请求流的方向。|默认值为 Direction::Output。<br>AudioStreamBuilder * |setSampleRate (int32_t sampleRate)|请求以 Hz 为单位的特定采样率。|默认值为 kUnspecified。如果未指定值，则应用程序应在打开流后查询实际值。<br>从技术上讲，这应该称为“帧速率”或“每秒帧数”，因为它指的是每秒传输的完整帧数。但它传统上称为“采样率”。<br>AudioStreamBuilder * |setFramesPerDataCallback (int framesPerCallback)|为数据回调请求特定数量的帧。|默认值为 kUnspecified。如果未指定该值，则实际数量可能因回调而异。如果应用程序可以处理不同数量的帧，那么我们建议不要指定它。这允许底层 API 优化回调。但是，例如，如果您的应用程序执行 FFT 或其他面向块的操作，则调用此函数以获得所需的大小。<br>AudioStreamBuilder * |setFormat (AudioFormat format)|请求示例数据格式，例如 Format::Float。|默认为格式::未指定。如果未指定值，则应用程序应在打开流后查询实际值。<br>AudioStreamBuilder * |setBufferCapacityInFrames (int32_t bufferCapacityInFrames)|以帧为单位设置请求的缓冲区容量。BufferCapacityInFrames 是最大可能的 BufferSizeInFrames。|最终的流容量可能不同。对于 AAudio，它至少应该有这么大。对于 OpenSL ES，它可以更小。<br>默认值为 kUnspecified。<br>AudioApi |getAudioApi () const|获取打开流时将请求的音频 API。|不能保证这是实际使用的 API。查询流本身以找出正在使用的 API。<br>如果不指定 API，则在 isAAudioRecommended() 返回 true 时将使用 AAudio。否则将使用 OpenSL ES。<br>AudioStreamBuilder * |setAudioApi (AudioApi audioApi)|如果您未指定此项，则 Oboe 将在运行时为设备和 SDK 版本选择最佳 API。|这应该几乎总是未指定，除了调试目的。<br>指定AAudio会强制 Oboe 在8.0上使用AAudio，风险极大。<br>指定 OpenSLES 应主要用于测试传统性能/功能。<br>如果调用方请求 AAudio 并且支持它，则将使用 AAudio。<br>AudioStreamBuilder * |setSharingMode (SharingMode sharingMode)|请求共享设备的模式。 请求的共享模式可能不可用。|所以应用程序应该在流打开后查询实际模式。<br>AudioStreamBuilder * |setPerformanceMode (PerformanceMode performanceMode)|请求流的性能级别。|这将决定延迟、功耗和故障保护级别。<br>AudioStreamBuilder * |setUsage (Usage usage)|设置输出流的预期用例。|系统将使用此信息来优化流的行为。例如，这可能会影响处理流的音量和焦点的方式。输入流的用法被忽略。如果不调用此函数，默认值为 Usage::Media。在 API 级别 28 中添加。<br>AudioStreamBuilder * |setContentType (ContentType contentType)|设置输出流将携带的音频数据的类型。|系统将使用此信息来优化流的行为。例如，这可能会影响通知发生时流是否暂停。输入流的 contentType 将被忽略。<br>如果不调用此函数，默认值为 ContentType::Music。<br>在 API 级别 28 中添加。<br>AudioStreamBuilder * |setInputPreset (InputPreset inputPreset)|设置流的输入（捕获）预设。|系统将使用此信息来优化流的行为。例如，这可能会影响使用哪些麦克风以及如何处理记录的数据。如果不调用此函数，默认值为 InputPreset::VoiceRecognition。这是因为 VoiceRecognition 是许多平台上延迟最低的预设。在 API 级别 28 中添加。<br>AudioStreamBuilder * |setSessionId (SessionId sessionId)|设置请求的会话 ID。|会话 ID 可用于将流与效果处理器相关联，使用 Android AudioEffect Java API 控制效果。<br>如果不调用此函数，默认值为 SessionId::None。如果设置为 SessionId::Allocate，则在打开流时将分配会话 ID。分配的会话 ID 可以通过调用 AudioStream::getSessionId() 获得，然后在打开另一个流时与此函数一起使用。 这允许在流之间共享效果。<br>来自 Oboe 的会话 ID 可用于 Android Java API，反之亦然。因此，可以将 Oboe 流中的会话 ID 传递给 Java，并使用 Java AudioEffect API 应用效果。分配的会话 ID 将始终为正且非零。<br>在 API 级别 28 中添加。<br>AudioStreamBuilder * |setDeviceId (int32_t deviceId)|在给定音频设备 ID 的情况下，向特定音频输入/输出设备请求流。|在大多数情况下，主要设备将是要使用的适当设备，并且可以将 deviceId 保留为 kUnspecified。<br>例如，在 Android 上，可以从 Java AudioManager 获取 ID。AudioManager.getDevices() 返回一个 AudioDeviceInfo[] 数组，其中包含一个 getId() 方法（以及其他类型信息），应该传递给这个方法。<br>请注意，当使用 OpenSL ES 时，这将被忽略并且创建的流将具有 deviceId kUnspecified。<br>AudioStreamBuilder * |setDataCallback (oboe::AudioStreamDataCallback *dataCallback)|指定一个对象来处理来自底层 API 的数据相关回调。<br>AudioStreamBuilder * |setErrorCallback (oboe::AudioStreamErrorCallback *errorCallback)|指定一个对象来处理来自底层 API 的错误相关回调。<br>当由于耳机插入或拔出而导致流断开时，可能会发生这种情况。<br>如果音频服务失败或独占流被另一个流窃取，也会发生这种情况。|当发生错误回调时，必须在单独的线程中停止并关闭关联的流。<br>AudioStreamBuilder * |setCallback (AudioStreamCallback *streamCallback)|指定一个对象来处理来自底层 API 的数据或与错误相关的回调。|这相当于调用 setDataCallback() 和 setErrorCallback()。<br>当发生错误回调时，关联的流将在单独的线程中停止并关闭。<br>AudioStreamBuilder * |setChannelConversionAllowed (bool allowed)|如果为真，则 Oboe 可能会转换通道数以达到最佳效果。例如，在某些版本的 Android 上，立体声流无法使用 FAST 轨道。因此可能会使用单声道流并复制到两个通道。在某些设备上，单声道流可能会中断，因此可能会打开立体声流并将其转换为单声道。<br>默认为真。<br>AudioStreamBuilder * |setFormatConversionAllowed (bool allowed)|如果为真，则 Oboe 可能会转换数据格式以获得最佳结果。|例如，在某些版本的 Android 上，浮动流无法获得低延迟数据路径。因此，可能会打开 I16 流并将其转换为浮点数。<br>默认为假。<br>AudioStreamBuilder * |setSampleRateConversionQuality (SampleRateConversionQuality quality)|在 Oboe 中指定采样率转换器的质量。|如果设置为 None 则 Oboe 不会进行采样率转换。但如果您指定采样率，底层 API 可能仍会进行采样率转换。这可能会阻止您获得低延迟流。如果您在 Oboe 中进行转换，那么您可能仍会获得低延迟流。默认为 SampleRateConversionQuality::None<br>bool |willUseAAudio () const|如果将根据当前设置使用 AAudio，则返回 true。<br>Result |openStream (std::shared_ptr&lt; oboe::AudioStream &gt; &amp;stream)|根据当前设置创建并打开流对象。|调用者共享指向 AudioStream 对象的指针。 shared_ptr 由 Oboe 内部使用，以防止流在回调使用时被删除。<br>Result |openManagedStream (ManagedStream &amp;stream)|根据当前构建器状态创建并打开 ManagedStream 对象。|调用者必须创建一个唯一的 ptr，并通过引用传递，以便可以修改它以指向一个打开的流。调用者拥有唯一的 ptr，超出范围会自动关闭删除。</p><p><strong>Static Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>static bool |isAAudioSupported ()|此设备是否支持 AAudio API？|Oreo 8.0 版本中引入了 AAudio。<br>static bool |isAAudioRecommended ()|推荐这款设备使用 AAudio API 吗？|由于版本特定问题，可能支持 AAudio 但不推荐使用。Android 8.0 或更早版本不建议使用 AAudio。</p><h3 id="oboeaudiostreamdatacallback"><a class="markdownIt-Anchor" href="#oboeaudiostreamdatacallback"></a> <strong>oboe::AudioStreamDataCallback</strong></h3><p>AudioStreamDataCallback 定义了一个回调接口，用于使用 onAudioReady 将数据移入/移出音频流使用 onError* 方法在流出现错误时发出警报。<br>它与 AudioStreamBuilder::setDataCallback() 一起使用。</p><p><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-hello-oboe/6.png" alt=""></p><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>virtual DataCallbackResult |onAudioReady (AudioStream *audioStream, void *audioData, int32_t numFrames)=0|缓冲区已准备好进行处理。|对于输出流，此函数应以流的当前数据格式呈现和写入 numFrames 数据到 audioData 缓冲区。<br>对于输入流，此函数应从 audioData 缓冲区读取和处理 numFrames 数据。<br>音频数据通过缓冲区传递。所以不要在进行回调的流上调用 read() 或 write() 。<br>请注意，除非调用 AudioStreamBuilder::setFramesPerCallback()，否则 numFrames 可能会有所不同。<br>另请注意，此回调函数应被视为“实时”函数。它不能做任何可能导致无限延迟的事情，因为这可能导致音频出现故障或爆裂。<br>如果您需要移动数据，例如。 MIDI 命令，传入或传出回调函数，然后我们建议使用非阻塞技术，例如原子 FIFO。</p><h3 id="oboeaudiostreamerrorcallback"><a class="markdownIt-Anchor" href="#oboeaudiostreamerrorcallback"></a> <strong>oboe::AudioStreamErrorCallback</strong></h3><p>AudioStreamErrorCallback 定义了一个回调接口，用于在流出现错误或使用 onError* 方法断开连接时收到警报。<br>它与 AudioStreamBuilder::setErrorCallback() 一起使用。</p><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>virtual bool |onError (AudioStream *, Result)|当流发生错误时，例如当流断开连接时，这将在其他 onError 方法之前调用。|它可用于覆盖和自定义正常的错误处理。使用这种方法被认为是一种先进的技术。例如，如果应用程序想要在关闭和重新打开流时使用高级锁，则可以使用它。或者，当应用程序想要向处理所有流状态的管理线程发送信号时，可能会使用它。<br>如果此方法返回 false，则表明流尚未被应用程序停止和关闭。在这种情况下，Oboe 将通过以下方式停止它：将调用 onErrorBeforeClose()，然后关闭流并关闭 onErrorAfterClose()。<br>如果此方法返回 true，则表示应用程序已停止并关闭流，并且 Oboe 不会这样做。在这种情况下，应用程序必须 stop() 和 close() 流。<br>该方法将在 Oboe 创建的线程上调用。<br>virtual void |onErrorBeforeClose (AudioStream *, Result)|当流上发生错误时，例如当流断开连接时，并且如果 onError() 返回 false（表示尚未处理错误）时，将调用此方法。|请注意，这将在 Oboe 创建的线程上调用。<br>底层流将在 Oboe 已停止但尚未关闭时调用。所以可以查询流。<br>不要在此方法中关闭或删除流，因为此方法返回后它将被关闭。<br>virtual void |onErrorAfterClose (AudioStream *, Result)|当流上发生错误时，例如当流断开连接时，并且如果 onError() 返回 false（表示尚未处理错误）时，将调用此方法。|底层 AAudio 或 OpenSL ES 流已被 Oboe 停止和关闭。因此无法引用底层流。但是您仍然可以查询大多数参数。此回调可用于在另一台设备上重新打开新流。</p><h3 id="oboestabilizedcallback"><a class="markdownIt-Anchor" href="#oboestabilizedcallback"></a> <strong>oboe::StabilizedCallback</strong></h3><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>  |StabilizedCallback (AudioStreamCallback *callback)|<br>DataCallbackResult |onAudioReady (AudioStream *oboeStream, void *audioData, int32_t numFrames) override|缓冲区已准备好进行处理。|Implements oboe::AudioStreamDataCallback.<br>void |onErrorBeforeClose (AudioStream *oboeStream, Result error) override|当流上发生错误时，例如当流断开连接时，并且如果 onError() 返回 false（表示尚未处理错误）时，将调用此方法。|Reimplemented from oboe::AudioStreamErrorCallback.<br>void |onErrorAfterClose (AudioStream *oboeStream, Result error) override|当流上发生错误时，例如当流断开连接时，并且如果 onError() 返回 false（表示尚未处理错误）时，将调用此方法。|Reimplemented from oboe::AudioStreamErrorCallback.</p><h3 id="oboedefaultstreamvalues"><a class="markdownIt-Anchor" href="#oboedefaultstreamvalues"></a> <strong>oboe::DefaultStreamValues</strong></h3><p>在 API 16 到 26 上，将使用 OpenSL ES。使用 OpenSL ES 时，本地代码不知道 sampleRate 和 framesPerBurst 的最佳值。在 API 17+ 上，应使用以下代码从 AudioManager 获取这些值：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-comment">// Note that this technique only works for built-in speakers and headphones.</span><br>AudioManager myAudioMgr = (AudioManager) getSystemService(Context.AUDIO_SERVICE);<br>String sampleRateStr = myAudioMgr.getProperty(AudioManager.PROPERTY_OUTPUT_SAMPLE_RATE);<br><span class="hljs-type">int</span> defaultSampleRate = Integer.parseInt(sampleRateStr);<br>String framesPerBurstStr = myAudioMgr.getProperty(AudioManager.PROPERTY_OUTPUT_FRAMES_PER_BUFFER);<br><span class="hljs-type">int</span> defaultFramesPerBurst = Integer.parseInt(framesPerBurstStr);<br></code></pre></td></tr></table></figure><p>然后它可以通过 JNI 传递给 Oboe。</p><p>AAudio 会从 HAL 获取最佳的 framesPerBurst 并忽略此值。</p><h3 id="oboeresultwithvalue-t"><a class="markdownIt-Anchor" href="#oboeresultwithvalue-t"></a> <strong>oboe::ResultWithValue&lt; T &gt;</strong></h3><p>ResultWithValue 可以存储操作的结果（OK 或错误）和值。</p><p>它是为调用者需要知道操作是否成功，以及如果成功则需要在操作期间获得的值的情况而设计的。</p><p>例如，当从流中读取时，调用者需要知道读取操作的结果，如果成功，读取了多少帧。请注意，ResultWithValue 可以作为布尔值进行评估，因此检查结果是否正常很简单。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C">ResultWithValue&lt;<span class="hljs-type">int32_t</span>&gt; resultOfRead = myStream.read(&amp;buffer, numFrames, timeoutNanoseconds);<br><span class="hljs-keyword">if</span> (resultOfRead) &#123;<br>    LOGD(<span class="hljs-string">&quot;Frames read: %d&quot;</span>, resultOfRead.value()); <br>&#125; <span class="hljs-keyword">else</span> &#123; <br>    LOGD(<span class="hljs-string">&quot;Error reading from stream: %s&quot;</span>, resultOfRead.error()); <br>&#125;<br></code></pre></td></tr></table></figure><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>  |ResultWithValue (oboe::Result error)|构造一个包含错误结果的 ResultWithValue。<br>  |ResultWithValue (T value)|构造一个包含 OK 结果和值的 ResultWithValue。<br>oboe::Result |error () const|得到结果。<br>T |value () const|获取值<br>  |operator bool () const|如果正常则返回 true<br>bool |operator ! () const|检查错误的快速方法。<br>  |operator Result () const|隐式转换为结果。|这可以轻松地与结果值进行比较。</p><p><strong>Static Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>static ResultWithValue&lt; T &gt; |createBasedOnSign (T numericResult)|从一个数字创建一个 ResultWithValue。|如果数字为正数，则 ResultWithValue 的结果为 Result::OK 并且该值将包含该数字。如果数字是负数，则结果将从负数中获得（数字错误代码可以在 AAudio.h 中找到）并且该值将为空。</p><h3 id="oboelatencytuner"><a class="markdownIt-Anchor" href="#oboelatencytuner"></a> <strong>oboe::LatencyTuner</strong></h3><p>LatencyTuner 可用于动态调整输出流的延迟。它通过监控欠载次数来调整流的 bufferSize。</p><p>这只会影响与最接近应用程序的第一级缓冲相关的延迟。它不会影响 HAL 中的低延迟或 UI 中的触摸延迟。</p><p>如果使用回调，请在从数据回调函数返回之前立即调用 tune()。如果使用阻塞写入，请在调用 write() 之前调用 tune()。</p><p>如果您想查看此调整过程的持续结果，请定期调用 stream-&gt;getBufferSize()。</p><p><strong>Public</strong></p><p>返回值|函数|描述|评论<br>–|–<br>  |LatencyTuner (AudioStream &amp;stream)|构造一个新的 LatencyTuner 对象，它将作用于给定的音频流<br>  |LatencyTuner (AudioStream &amp;stream, int32_t maximumBufferSize)|构造一个新的 LatencyTuner 对象，它将作用于给定的音频流|可指定最大值<br>Result |tune ()|调整 bufferSizeInFrames 以优化延迟。|它将以低延迟开始，然后在发生欠载时提高它。仅 AAudio 支持延迟调整。<br>void |requestReset ()|这可以从另一个线程调用。然后 tune() 将调用 reset()，这会将延迟降低到最低限度，然后在出现故障时允许它回升。|这通常是为了响应用户决定最小化延迟而调用的。换句话说，从按钮处理程序调用它。<br>bool |isAtMaximumBufferSize ()|如果音频流的缓冲区大小为最大值，则返回 true。|如果在构造 LatencyTuner 时未指定最大值，则使用 stream-&gt;getBufferCapacityInFrames 的值<br>void |setMinimumBufferSize (int32_t bufferSize)|设置调谐器重置时使用的最小缓冲区大小（以帧为单位）。|您可能希望在调用它之后调用 request Reset()。<br>int32_t |getMinimumBufferSize () const|<br>void |setBufferSizeIncrement (int32_t sizeIncrement)|设置调整时缓冲区大小将增加的数量。默认情况下，这将是一次突发。|请注意，AAudio 会将缓冲区大小量化为 burstSize 的倍数。所以最终的缓冲区大小可能不是这个增量的倍数。<br>int32_t |getBufferSizeIncrement () const|</p><h3 id="oboeoboeglobals"><a class="markdownIt-Anchor" href="#oboeoboeglobals"></a> <strong>oboe::OboeGlobals</strong></h3><p><strong>Static Public</strong></p><p>返回值|函数|描述<br>–|–<br>static bool |areWorkaroundsEnabled ()<br>static void |setWorkaroundsEnabled (bool enabled)|在编写测试重现 AAudio 或 OpenSL ES 中的错误时禁用此功能，这些错误在 Oboe 中具有变通方法。</p><hr><h1 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> <strong>代码</strong></h1><p><a target="_blank" rel="noopener" href="http://colors.black:10086/0/oboe/tree/main/samples/LiveEffect" title="http://colors.black:10086/0/oboe/tree/main/samples/LiveEffect">LiveEffect</a></p><hr><h1 id="分析"><a class="markdownIt-Anchor" href="#分析"></a> <strong>分析</strong></h1><p><img src="https://weichao-io-1257283924.cos.ap-beijing.myqcloud.com/qldownload/Android-NDK-sample-%E4%B9%8B-LiveEffect/Android-NDK-sample-%E4%B9%8B-LiveEffect2.jpg" alt=""></p><hr></div><hr><div><div class="post-metas my-3"></div><div class="license-box my-3"><div class="license-title"><div>Android NDK sample 之 LiveEffect</div><div>https://weichao.io/45e4270bb397/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>魏超</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2021年8月29日</div></div><div class="license-meta-item license-meta-date"><div>更新于</div><div>2022年12月4日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i> </span></a><a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="NC - 非商业性使用"><i class="iconfont icon-nc"></i> </span></a><a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="SA - 相同方式共享"><i class="iconfont icon-sa"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/c8e18aa2201a/" title="Android NDK sample 之 SoundBoard"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Android NDK sample 之 SoundBoard</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/9a2c5ee31f69/" title="Android NDK sample 之 MegaDrone"><span class="hidden-mobile">Android NDK sample 之 MegaDrone</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><i class="iconfont icon-my-hexo"></i>&nbsp;<span>博客框架Hexo&nbsp;&nbsp;</span></a> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><i class="iconfont icon-my-theme"></i>&nbsp;<span>博客主题Fluid&nbsp;&nbsp;</span></a> <a href="https://weichao.io" target="_blank" rel="nofollow noopener"><i class="iconfont icon-my-copyright"></i>&nbsp;2022<span>魏超</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>